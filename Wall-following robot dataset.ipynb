{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall-following robot dataset\n",
    "## Author: Ananda Freire, Marcus Veloso and Guilherme Barreto  Source: [original]\n",
    "## (http://www.openml.org/d/1497) - UCI  Please cite:  \n",
    "### * Dataset Title:   Wall-Following Robot Navigation Data Data Set (version with 2 Attributes) \n",
    "### * Abstract:   The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.  \n",
    "### * Source:  (a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto  Department of Teleinformatics Engineering  Federal University of CearÃ¡  Fortaleza, CearÃ¡, Brazil   (b) Donors of database: Ananda Freire (anandalf '@' gmail.com)  Guilherme Barreto (guilherme '@' deti.ufc.br)  \n",
    "* Data Set Information:  The provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second.   It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step).   The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions.   If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network.  \n",
    "#### * Attribute Information: \n",
    "##### Number of Attributes: sensor_readings_2.data: 2 numeric attributes and the class.  \n",
    "##### For Each Attribute:  -- File sensor_readings_2.data:  \n",
    "###### 1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)  \n",
    "###### 2. SD_left: minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real)  \n",
    "###### 3. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data/wall-robot-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"Class\"]\n",
    "features = data[list([\"V1\", \"V2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.15)\n",
    "StSc = StandardScaler()\n",
    "StSc.fit(X_train)\n",
    "X_train_std = StSc.transform(X_train)\n",
    "X_test_std = StSc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear perceptron accuracy with 50 epochs:  0.8754578754578755\n"
     ]
    }
   ],
   "source": [
    "linear_perceptron = Perceptron(max_iter=50, eta0=0.1)\n",
    "linear_perceptron.fit(X_train_std, y_train)\n",
    "print (\"Linear perceptron accuracy with 50 epochs: \", accuracy_score(linear_perceptron.predict(X_test_std), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer perceptron accuracy with 50 epochs:  0.9499389499389499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "multilayer_perceptron = MLPClassifier(solver='adam', alpha=0.01, hidden_layer_sizes=(10, 5, 2), random_state=1, max_iter=50)\n",
    "multilayer_perceptron.fit(X_train_std, y_train)\n",
    "print (\"Multilayer perceptron accuracy with 50 epochs: \", accuracy_score(multilayer_perceptron.predict(X_test_std), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encoding\n",
    "n_labels = np.max(labels) + 1\n",
    "labellist = np.eye(n_labels)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple LSTM same task\n",
    "import keras\n",
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Embedding(10, 1, input_length=2))\n",
    "#model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.LSTM(units=3, return_sequences=True))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.02),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5456/5456 [==============================] - 5s 1ms/step - loss: 0.7454 - acc: 0.7322\n",
      "Epoch 2/10\n",
      "5456/5456 [==============================] - 2s 429us/step - loss: 0.5630 - acc: 0.7828\n",
      "Epoch 3/10\n",
      "5456/5456 [==============================] - 2s 437us/step - loss: 0.5582 - acc: 0.7828\n",
      "Epoch 4/10\n",
      "5456/5456 [==============================] - 3s 461us/step - loss: 0.5563 - acc: 0.7823\n",
      "Epoch 5/10\n",
      "5456/5456 [==============================] - 3s 458us/step - loss: 0.5548 - acc: 0.7824\n",
      "Epoch 6/10\n",
      "5456/5456 [==============================] - 3s 467us/step - loss: 0.5570 - acc: 0.7830\n",
      "Epoch 7/10\n",
      "5456/5456 [==============================] - 2s 445us/step - loss: 0.5535 - acc: 0.7826\n",
      "Epoch 8/10\n",
      "5456/5456 [==============================] - 2s 445us/step - loss: 0.5533 - acc: 0.7826\n",
      "Epoch 9/10\n",
      "5456/5456 [==============================] - 2s 440us/step - loss: 0.5529 - acc: 0.7826\n",
      "Epoch 10/10\n",
      "5456/5456 [==============================] - 2s 451us/step - loss: 0.5518 - acc: 0.7824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32169668>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, labellist, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
