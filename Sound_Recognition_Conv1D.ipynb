{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sound_Recognition_Conv1D.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renowator/My_ML/blob/master/Sound_Recognition_Conv1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BUds2-EoZ3N",
        "colab_type": "text"
      },
      "source": [
        "**Upload the sample files to Google Colab and extract .zip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7jXI2-o4VHI",
        "colab_type": "code",
        "outputId": "fd38fcba-0399-40c8-8e8c-4417a37fcfd3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b2ebe54-8086-4250-bf71-c4a64066e0e0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8b2ebe54-8086-4250-bf71-c4a64066e0e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHSMEZfP4kL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip Samples.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smqYY5Xkojip",
        "colab_type": "text"
      },
      "source": [
        "Load the files to a list and add corresponding label. *Skip problematic files*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm9JWZsb4m0v",
        "colab_type": "code",
        "outputId": "0f22baeb-dfa3-4eb7-d7cb-088ff454b12c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import os\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "data = []\n",
        "labels = []\n",
        "directory = './Samples/Kicks/'\n",
        "!cd Samples/Kicks\n",
        "for filename in os.listdir(directory):\n",
        "  try:\n",
        "    if filename.endswith(\".wav\") or filename.endswith(\".WAV\"):\n",
        "        fs, new_data = wavfile.read(directory + filename)\n",
        "        data.append(np.array(new_data))\n",
        "        labels.append(0)\n",
        "        continue\n",
        "    else:\n",
        "      continue\n",
        "  except:\n",
        "    print(\"Oops\")\n",
        "    continue\n",
        "    \n",
        "directory = './Samples/Snares/'\n",
        "for filename in os.listdir(directory):\n",
        "  try:\n",
        "    if filename.endswith(\".wav\") or filename.endswith(\".WAV\"):\n",
        "        fs, new_data = wavfile.read(directory + filename)\n",
        "        data.append(np.array(new_data))\n",
        "        labels.append(1)\n",
        "        continue\n",
        "    else:\n",
        "        continue\n",
        "  except:\n",
        "    print(\"Oops\")\n",
        "    continue\n",
        "directory = './Samples/HHT/'\n",
        "for filename in os.listdir(directory):\n",
        "  try:\n",
        "    if filename.endswith(\".wav\") or filename.endswith(\".WAV\"):\n",
        "        fs, new_data = wavfile.read(directory + filename)\n",
        "        data.append(np.array(new_data))\n",
        "        labels.append(2)\n",
        "        continue\n",
        "    else:\n",
        "        continue\n",
        "  except:\n",
        "    print(\"Oops\")\n",
        "    continue\n",
        "    \n",
        "    \n",
        "print(len(data), len(labels))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  WavFileWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "Oops\n",
            "466 466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5jHvVsdo1v7",
        "colab_type": "text"
      },
      "source": [
        "Remove items with unusual shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTtPLt88mm2s",
        "colab_type": "code",
        "outputId": "94f9cf5b-614b-489e-bb02-32bd1d0eb267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "\n",
        "for i, item in enumerate(data):\n",
        "  if len(item.shape) != 2:\n",
        "    del data[i]\n",
        "    del labels[i]\n",
        "    print(len(data))\n",
        "    print(len(labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "465\n",
            "465\n",
            "464\n",
            "464\n",
            "463\n",
            "463\n",
            "462\n",
            "462\n",
            "461\n",
            "461\n",
            "460\n",
            "460\n",
            "459\n",
            "459\n",
            "458\n",
            "458\n",
            "457\n",
            "457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwolZNQfo93B",
        "colab_type": "text"
      },
      "source": [
        "Process items to give them same size (size of max file+220) and put into numpy array for further processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hlj2-EP51Xv",
        "colab_type": "code",
        "outputId": "f7110054-e243-43f5-ee75-fe29834550b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "desired_shape = (np.max([np.max(item.shape) for item in data ]) + 220 , 2)\n",
        "print(desired_shape)\n",
        "processed_data = None\n",
        "for i, item in enumerate(data):\n",
        "  if (len(item.shape) == 2):\n",
        "    result = np.zeros(desired_shape).astype(np.int16)\n",
        "    result[:item.shape[0],:item.shape[1]] = item.astype(np.int16)\n",
        "    result = result.reshape((1, desired_shape[0], desired_shape[1]))\n",
        "    if processed_data is None:\n",
        "      processed_data = result\n",
        "    else:\n",
        "      print(\"\\r\"+str( result.shape) + \" ==> \" + str(processed_data.shape), end=\"\")\n",
        "      processed_data = np.append(processed_data, result, axis=0)\n",
        "  else:\n",
        "    del labels[i]\n",
        "print(processed_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1254620, 2)\n",
            "(1, 1254620, 2) ==> (455, 1254620, 2)(456, 1254620, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZKU1gtqFkxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "labels = np.array(labels).astype(np.int16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsKqOmRQpPWw",
        "colab_type": "text"
      },
      "source": [
        "Now we need to get processed_data to be in range of [-1;1] instead of current [-32000; 32000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvN2AaLa6RwG",
        "colab_type": "code",
        "outputId": "148be01b-bdc2-4656-a39d-805fe340ce64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "processed_data[200]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0],\n",
              "       [-451, -489],\n",
              "       [  48,   39],\n",
              "       ...,\n",
              "       [   0,    0],\n",
              "       [   0,    0],\n",
              "       [   0,    0]], dtype=int16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHZ8_RQq7BTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_val = np.max(processed_data)\n",
        "processed_data = processed_data.astype(np.float16)\n",
        "processed_data = processed_data/max_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-a70GeROhTN",
        "colab_type": "code",
        "outputId": "041105cb-40ef-4e70-bb35-564f00425e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "processed_data[200]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ],\n",
              "       [-0.01376385, -0.01492355],\n",
              "       [ 0.00146489,  0.00119022],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrwQUkdliSOz",
        "colab_type": "code",
        "outputId": "7033437d-4834-4338-a658-96ed30d1a10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "categorical_labels = to_categorical(labels, num_classes=3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3DBFJMX7Q1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrcknKof861g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## extra imports to set GPU options\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        " \n",
        "###################################\n",
        "# TensorFlow wizardry\n",
        "config = tf.ConfigProto()\n",
        " \n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config.gpu_options.allow_growth = True\n",
        " \n",
        "# Only allow a total of half the GPU memory to be allocated\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
        "config.inter_op_parallelism_threads=4\n",
        "config.intra_op_parallelism_threads=4\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "###################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqYFQqtTp5c3",
        "colab_type": "text"
      },
      "source": [
        "**Create a NN model utilizing AveragePooling(for incoming samples); Temporal 1D convolutions and MaxPooling layers and finish with Fully Connected layer and Softmax output layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFRbQS5k88jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=(desired_shape[0], desired_shape[1])))\n",
        "model.add(tf.keras.layers.AveragePooling1D(22, 2))\n",
        "model.add(tf.keras.layers.Conv1D(4, 3, 2, \"valid\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling1D(3, 2))\n",
        "model.add(tf.keras.layers.Conv1D(16, 3, 2, \"valid\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling1D(3, 2))\n",
        "model.add(tf.keras.layers.Conv1D(64, 3, 2, \"valid\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling1D(3, 2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB4RaU9E-dZf",
        "colab_type": "code",
        "outputId": "969d5e4a-ea89-438b-9aef-2eb89b8c31ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "opt = tf.keras.optimizers.RMSprop(lr=0.002)\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "average_pooling1d_7 (Average (None, 627300, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 313649, 4)         28        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 156824, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 78411, 16)         208       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 39205, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 19602, 64)         3136      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 9800, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 627200)            0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 16)                10035216  \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 10,038,639\n",
            "Trainable params: 10,038,639\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGPiZrCC_NAh",
        "colab_type": "code",
        "outputId": "abd2a0e0-5d75-4c0e-c963-1f3313913733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "source": [
        "# checkpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(processed_data, categorical_labels, epochs=20, verbose=1, validation_split=0.2, batch_size= 16, shuffle=True, callbacks=callbacks_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 364 samples, validate on 92 samples\n",
            "Epoch 1/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.8128 - acc: 0.6648\n",
            "Epoch 00001: val_loss improved from inf to 2.67035, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 5s 15ms/sample - loss: 0.8038 - acc: 0.6676 - val_loss: 2.6703 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8295\n",
            "Epoch 00002: val_loss improved from 2.67035 to 2.11387, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.3926 - acc: 0.8297 - val_loss: 2.1139 - val_acc: 0.0000e+00\n",
            "Epoch 3/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.3403 - acc: 0.8778\n",
            "Epoch 00003: val_loss improved from 2.11387 to 0.69377, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.3419 - acc: 0.8791 - val_loss: 0.6938 - val_acc: 0.8804\n",
            "Epoch 4/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.8665\n",
            "Epoch 00004: val_loss improved from 0.69377 to 0.61953, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.3035 - acc: 0.8626 - val_loss: 0.6195 - val_acc: 0.9674\n",
            "Epoch 5/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9261\n",
            "Epoch 00005: val_loss did not improve from 0.61953\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.1908 - acc: 0.9286 - val_loss: 0.8321 - val_acc: 0.6630\n",
            "Epoch 6/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9205\n",
            "Epoch 00006: val_loss did not improve from 0.61953\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.2863 - acc: 0.9203 - val_loss: 0.7694 - val_acc: 0.8696\n",
            "Epoch 7/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9432\n",
            "Epoch 00007: val_loss did not improve from 0.61953\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.1927 - acc: 0.9451 - val_loss: 1.7656 - val_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9176\n",
            "Epoch 00008: val_loss did not improve from 0.61953\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.1740 - acc: 0.9203 - val_loss: 1.1712 - val_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9460\n",
            "Epoch 00009: val_loss improved from 0.61953 to 0.55035, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.1280 - acc: 0.9451 - val_loss: 0.5503 - val_acc: 0.8804\n",
            "Epoch 10/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9375\n",
            "Epoch 00010: val_loss did not improve from 0.55035\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.1351 - acc: 0.9396 - val_loss: 0.8023 - val_acc: 0.7391\n",
            "Epoch 11/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9659\n",
            "Epoch 00011: val_loss did not improve from 0.55035\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.1066 - acc: 0.9670 - val_loss: 3.2098 - val_acc: 0.0000e+00\n",
            "Epoch 12/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9744\n",
            "Epoch 00012: val_loss did not improve from 0.55035\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.0663 - acc: 0.9725 - val_loss: 1.3258 - val_acc: 0.1848\n",
            "Epoch 13/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.9347\n",
            "Epoch 00013: val_loss improved from 0.55035 to 0.45740, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.5421 - acc: 0.9368 - val_loss: 0.4574 - val_acc: 0.8804\n",
            "Epoch 14/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9801\n",
            "Epoch 00014: val_loss improved from 0.45740 to 0.36124, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.0505 - acc: 0.9808 - val_loss: 0.3612 - val_acc: 0.8913\n",
            "Epoch 15/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9830\n",
            "Epoch 00015: val_loss improved from 0.36124 to 0.31506, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.0672 - acc: 0.9835 - val_loss: 0.3151 - val_acc: 0.9348\n",
            "Epoch 16/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9773\n",
            "Epoch 00016: val_loss improved from 0.31506 to 0.18483, saving model to weights.best.hdf5\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.0752 - acc: 0.9780 - val_loss: 0.1848 - val_acc: 0.9565\n",
            "Epoch 17/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9773\n",
            "Epoch 00017: val_loss did not improve from 0.18483\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.0611 - acc: 0.9780 - val_loss: 0.2142 - val_acc: 0.9674\n",
            "Epoch 18/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9744\n",
            "Epoch 00018: val_loss did not improve from 0.18483\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.1048 - acc: 0.9753 - val_loss: 1.3644 - val_acc: 0.0000e+00\n",
            "Epoch 19/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9773\n",
            "Epoch 00019: val_loss did not improve from 0.18483\n",
            "364/364 [==============================] - 4s 12ms/sample - loss: 0.1245 - acc: 0.9780 - val_loss: 0.1882 - val_acc: 0.9565\n",
            "Epoch 20/20\n",
            "352/364 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.9602\n",
            "Epoch 00020: val_loss did not improve from 0.18483\n",
            "364/364 [==============================] - 4s 11ms/sample - loss: 0.2348 - acc: 0.9615 - val_loss: 0.2856 - val_acc: 0.9239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2631fb2320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYDug_Wyq3qt",
        "colab_type": "text"
      },
      "source": [
        "Load the weights with best validation performance and save our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wjfooi9HSKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"weights.best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCMYCiclRL4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('sound_rec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1NmPqb4RVmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "#files.download('sound_rec_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYwM4UqirQ3H",
        "colab_type": "text"
      },
      "source": [
        "Now we can test the Classification accuracy with other samples not used in training/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yURe2NxVdtU",
        "colab_type": "code",
        "outputId": "49b678f5-4600-4eff-e501-45648021f2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "\n",
        "fs, data = wavfile.read('Phonotix Kick 1.wav')\n",
        "test_data = np.array(data).astype(np.int16)\n",
        "result = np.zeros(desired_shape).astype(np.float16)\n",
        "result[:test_data.shape[0],:test_data.shape[1]] = test_data/max_val\n",
        "test_data = result.reshape((1, desired_shape[0], desired_shape[1]))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  WavFileWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SFZKJxVWa9z",
        "colab_type": "code",
        "outputId": "e34b0ae1-deeb-4ca3-ae8e-c49610c5f83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(model.predict(test_data))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5UjJpNUWfjt",
        "colab_type": "code",
        "outputId": "f912e61a-d246-4fc0-ade3-b04ce107b82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict(processed_data[0].reshape(1, 1254620, 2))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9944061e-01, 5.5938511e-04, 1.0140273e-09]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYTTyPNn3csM",
        "colab_type": "code",
        "outputId": "995b3a5a-3af6-4325-e24a-2a5d74cf2a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict(processed_data[250].reshape(1, 1254620, 2))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0671884e-04, 9.9989259e-01, 6.5943419e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Nfp0DB4Gfb",
        "colab_type": "code",
        "outputId": "fff720e6-bf54-466e-91e7-35f6ef617bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict(processed_data[400].reshape(1, 1254620, 2))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00523018, 0.08496662, 0.90980315]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3TfPzTyIIld",
        "colab_type": "code",
        "outputId": "19f10f27-7284-4154-ebe3-6e7a22eab199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test_data[0][0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHeD-sNofSSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}